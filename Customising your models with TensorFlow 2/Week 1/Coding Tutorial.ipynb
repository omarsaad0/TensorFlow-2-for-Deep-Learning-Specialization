{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Keras functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Coding tutorials\n",
    " #### [1. Multiple inputs and outputs](#coding_tutorial_1)\n",
    " #### [2. Tensors and Variables](#coding_tutorial_2)\n",
    " #### [3. Accessing model layers](#coding_tutorial_3)\n",
    " #### [4. Freezing layers](#coding_tutorial_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Multiple inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the acute inflammations dataset\n",
    "\n",
    "The `acute inflammations` was created by a medical expert as a data set to test the expert system, which will perform the presumptive diagnosis of two diseases of the urinary system. You can find out more about the dataset [here](https://archive.ics.uci.edu/ml/datasets/Acute+Inflammations).\n",
    "\n",
    "Attribute information:\n",
    "\n",
    "Inputs:\n",
    "- Temperature of patient : 35C-42C\n",
    "- Occurrence of nausea : yes/no\n",
    "- Lumbar pain : yes/no\n",
    "- Urine pushing (continuous need for urination) : yes/no\n",
    "- Micturition pains : yes/no\n",
    "- Burning of urethra, itch, swelling of urethra outlet : yes/no\n",
    "\n",
    "Outputs:\n",
    "- decision 1: Inflammation of urinary bladder : yes/no\n",
    "- decision 2: Nephritis of renal pelvis origin : yes/no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd_dat = pd.read_csv('data/diagnosis.csv')\n",
    "dataset = pd_dat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build train and test data splits\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,:6], dataset[:,6:], test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assign training and testing inputs/outputs\n",
    "\n",
    "temp_train, nocc_train, lumbp_train, up_train, mict_train, bis_train = np.transpose(X_train)\n",
    "temp_test, nocc_test, lumbp_test, up_test, mict_test, bis_test = np.transpose(X_test)\n",
    "\n",
    "inflam_train, nephr_train = Y_train[:, 0], Y_train[:, 1]\n",
    "inflam_test, nephr_test = Y_test[:, 0], Y_test[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build the input layers\n",
    "\n",
    "from tensorflow.keras import Input, layers\n",
    "\n",
    "shape_input = (1,)\n",
    "temperature = Input(shape=shape_input, name='temp')\n",
    "nausea_occurence = Input(shape=shape_input, name='nocc')\n",
    "lumbar_pain = Input(shape=shape_input, name='lumbp')\n",
    "urine_pushing = Input(shape=shape_input, name='up')\n",
    "micturition_pains = Input(shape=shape_input, name='mict')\n",
    "bis = Input(shape=shape_input, name='bis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list of all the inputs\n",
    "\n",
    "list_inputs = [temperature, nausea_occurence, lumbar_pain, urine_pushing, \n",
    "               micturition_pains, bis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge all input features into a single large vector\n",
    "\n",
    "x = layers.concatenate(list_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use a logistic regression classifier for disease prediction\n",
    "\n",
    "inflammation_pred = layers.Dense(1, activation='sigmoid', name='inflam')(x)\n",
    "nephritis_pred = layers.Dense(1, activation='sigmoid', name='nephr')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list of all the outputs\n",
    "\n",
    "list_outputs = [inflammation_pred, nephritis_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the model object\n",
    "\n",
    "model = tf.keras.Model(inputs=list_inputs, outputs = list_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the multiple input/output model\n",
    "\n",
    "tf.keras.utils.plot_model(model, 'multi_input_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-3),\n",
    "             loss=['binary_crossentropy','binary_crossentropy'],\n",
    "             metrics=[['acc'],['mse']],\n",
    "             loss_weights=[1., 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define training inputs and outputs\n",
    "\n",
    "inputs_train = {'temp': temp_train, 'nocc': nocc_train, 'lumbp': lumbp_train,\n",
    "                'up': up_train, 'mict': mict_train, 'bis': bis_train}\n",
    "\n",
    "outputs_train = {'inflam': inflam_train, 'nephr': nephr_train}\n",
    "\n",
    "#inputs_train = [temp_train, nocc_train, lumbp_train, mict_train, bis_train]\n",
    "#outputs_train = [inflam_train, nephr_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(inputs_train, outputs_train,\n",
    "                   epochs=1000,\n",
    "                   batch_size=128,\n",
    "                   verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the training accuracy\n",
    "\n",
    "acc_keys = [k for k in history.history.keys() if k in ('inflam_acc', 'nephr_acc')] \n",
    "loss_keys = [k for k in history.history.keys() if not k in acc_keys]\n",
    "\n",
    "for k, v in history.history.items():\n",
    "    if k in acc_keys:\n",
    "        plt.figure(1)\n",
    "        plt.plot(v)\n",
    "    else:\n",
    "        plt.figure(2)\n",
    "        plt.plot(v)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(acc_keys, loc='upper right')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loss_keys, loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate([temp_test, nocc_test, lumbp_test, up_test, mict_test, bis_test], \n",
    "               [inflam_test, nephr_test],\n",
    "               verbose=2)\n",
    "#model.evaluate([temp_test, nocc_test, lumbp_test, up_test, mict_test, bis_test],\n",
    "               #[inflam_test, nephr_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Tensors and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Variable objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create Variable objects of different type with tf.Variable\n",
    "\n",
    "strings = tf.Variable([\"Hello world!\"], tf.string)\n",
    "floats  = tf.Variable([3.14159, 2.71828], tf.float64)\n",
    "ints = tf.Variable([1, 2, 3], tf.int32)\n",
    "complexs = tf.Variable([25.9 - 7.39j, 1.23 - 4.91j], tf.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialise a Variable value\n",
    "\n",
    "tf.Variable(tf.constant(4.3, shape=(3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use and modify Variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use the value of a Variable\n",
    "\n",
    "v = tf.Variable(0.0)\n",
    "w = v + 1  # w is a tf.Tensor which is computed based on the value of v.\n",
    "\n",
    "print(type(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Increment the value of a Variable\n",
    "\n",
    "v.assign_add(1)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Decrement the value of a Variable\n",
    "\n",
    "v.assign_sub(1)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Tensor objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a constant tensor and print its type as well as its shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a constant Tensor\n",
    "\n",
    "x = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(x)\n",
    "print(\"dtype:\", x.dtype)\n",
    "print(\"shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Obtain the value as a numpy array\n",
    "\n",
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a Tensor of type float32\n",
    "\n",
    "x = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create coefficients\n",
    "\n",
    "coeffs = np.arange(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise shapes\n",
    "\n",
    "shape1 = [8,2]\n",
    "shape2 = [4,4]\n",
    "shape3 = [2,2,2,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensors of different shape\n",
    "\n",
    "a = tf.constant(coeffs, shape=shape1)\n",
    "print(\"\\n a:\\n \", a)\n",
    "\n",
    "b = tf.constant(coeffs, shape=shape2)\n",
    "print(\"\\n b:\\n \", b)\n",
    "\n",
    "c = tf.constant(coeffs, shape=shape3)\n",
    "print(\"\\n c:\\n \", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a constant Tensor\n",
    "\n",
    "t = tf.constant(np.arange(80), shape=[5,2,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rank of a Tensor\n",
    "\n",
    "rank = tf.rank(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the rank\n",
    "\n",
    "print(\"rank: \", rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reshape a Tensor\n",
    "\n",
    "t2 = tf.reshape(t, [8,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the new shape\n",
    "\n",
    "print(\"t2.shape: \", t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create ones, zeros, identity and constant Tensors\n",
    "\n",
    "ones = tf.ones(shape=(2,3))\n",
    "zeros = tf.zeros(shape=(2,4))\n",
    "eye = tf.eye(3)\n",
    "tensor7 = tf.constant(7.0, shape=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the created tensors\n",
    "\n",
    "print(\"\\n Ones:\\n \", ones)\n",
    "print(\"\\n Zeros:\\n \", zeros)\n",
    "print(\"\\n Identity:\\n \", eye)\n",
    "print(\"\\n Tensor filled with 7: \", tensor7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a ones Tensor and a zeros Tensor\n",
    "\n",
    "t1 = tf.ones(shape=(2, 2))\n",
    "t2 = tf.zeros(shape=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Concatentate two Tensors\n",
    "\n",
    "concat0 = tf.concat([t1,t2],0)\n",
    "concat1 = tf.concat([t1,t2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the concatenated tensors\n",
    "\n",
    "print(concat0)\n",
    "print(concat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a constant Tensor\n",
    "\n",
    "t = tf.constant(np.arange(24), shape=(3, 2, 4))\n",
    "print(\"\\n t shape: \", t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Expanding the rank of Tensors\n",
    "\n",
    "t1 = tf.expand_dims(t,0) # the position of the added dim [0]\n",
    "t2 = tf.expand_dims(t,1) # the position of the added dim [1]\n",
    "t3 = tf.expand_dims(t,3) # the position of the added dim [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the shapes after tf.expand_dims\n",
    "\n",
    "print(\"\\n After expanding dims:\\n t1 shape: \", t1.shape, \"\\n t2 shape: \", t2.shape, \"\\n t3 shape: \", t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Squeezing redundant dimensions\n",
    "\n",
    "t1 = tf.squeeze(t1,0)\n",
    "t2 = tf.squeeze(t2,1)\n",
    "t3 = tf.squeeze(t3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the shapes after tf.squeeze\n",
    "\n",
    "print(\"\\n After squeezing:\\n t1 shape: \", t1.shape, \"\\n t2 shape: \", t2.shape, \"\\n t3 shape: \", t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Slicing a Tensor\n",
    "\n",
    "x = tf.constant([1,2,3,4,5,6,7])\n",
    "print(x[1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing maths with Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two constant Tensors\n",
    "\n",
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "d = tf.constant([[1.0, 1.0], [0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "matmul_cd = tf.matmul(c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the result\n",
    "\n",
    "print(\"\\n tf.matmul(c,d):\\n\", matmul_cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Elementwise operations\n",
    "\n",
    "c_times_d = c*d\n",
    "c_plus_d = c+d\n",
    "c_minus_d = c-d\n",
    "c_div_c = c/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "\n",
    "print(\"\\n c*d:\\n\", c_times_d)\n",
    "print(\"\\n c+d:\\n\", c_plus_d)\n",
    "print(\"\\n c-d:\\n\", c_minus_d)\n",
    "print(\"\\n c/c:\\n\", c_div_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create Tensors\n",
    "\n",
    "a = tf.constant([[2, 3], [3, 3]])\n",
    "b = tf.constant([[8, 7], [2, 3]])\n",
    "x = tf.constant([[-6.89 + 1.78j], [-2.54 + 2.15j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute value of a Tensor\n",
    "\n",
    "absx = tf.abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power of a Tensor\n",
    "\n",
    "powaa = tf.pow(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the results\n",
    "\n",
    "print(\"\\n \", absx)\n",
    "print(\"\\n \", powaa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly sampled constant tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a Tensor with samples from a Normal distribution\n",
    "\n",
    "tn = tf.random.normal(shape=(2,2), mean=0, stddev=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a Tensor with samples from a Uniform distribution\n",
    "\n",
    "tu = tf.random.uniform(shape=(2,1), minval=0, maxval=10, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a Tensor with samples from a Poisson distribution\n",
    "\n",
    "tp = tf.random.poisson((2,2),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# More maths operations\n",
    "\n",
    "d = tf.square(tn)\n",
    "e = tf.exp(d)\n",
    "f = tf.cos(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## Accessing model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we aim to demonstrate accessing layer attributes within a model.\n",
    "\n",
    "Let's get started by loading the `VGG19` pre-trained model from the `keras.applications` library, which is a very deep network trained on more than a million images from the ImageNet database. The network is trained to classify images into 1000 object categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the VGG19 model\n",
    "\n",
    "#from tensorflow.keras.applications import VGG19\n",
    "#vgg_model = VGG19()\n",
    "from tensorflow.keras.models import load_model\n",
    "vgg_model = load_model('models/Vgg19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inputs, layers and display the summary\n",
    "\n",
    "vgg_input = vgg_model.input\n",
    "vgg_layers = vgg_model.layers\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model to access the layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build a model that returns the layer outputs\n",
    "layer_outputs = [layer.output for layer in vgg_layers]\n",
    "features = Model(inputs=vgg_input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "tf.keras.utils.plot_model(features, 'vgg19_model.png', show_shapes = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test the model on a random input\n",
    "img = np.random.random((1,224,224,3)).astype('float32')\n",
    "extracted_features = features(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the 'cool cat' picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Zambia’s South Luangwa National Park, a photographer had been watching a pride of lions while they slept off a feast from a buffalo kill. When this female walked away, he anticipated that she might be going for a drink and so he positioned his vehicle on the opposite side of the waterhole. The `cool cat` picture is one of the highly commended 2018 Image from Wildlife Photographer of the Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the original image\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "display.display(Image.open('data/cool_cat.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise network features from the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img_path = 'data/cool_cat.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0) #no of batch\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract the features\n",
    "\n",
    "extracted_features = features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualise the input channels\n",
    "\n",
    "f1 = extracted_features[0]\n",
    "print('\\n f1.shape: ',f1.shape)\n",
    "\n",
    "imgs = f1[0,:,:]\n",
    "plt.figure(figsize=(15,15))\n",
    "for n in range(3):\n",
    "    ax = plt.subplot(1,3,n+1)\n",
    "    plt.imshow(imgs[:,:,n])\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(wspace=0.01,hspace=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualise some features in the first hidden layer\n",
    "\n",
    "# Visualise the input channels\n",
    "\n",
    "f2 = extracted_features[1]\n",
    "print('\\n f1.shape: ',f2.shape)\n",
    "\n",
    "imgs = f2[0,:,:]\n",
    "plt.figure(figsize=(15,15))\n",
    "for n in range(16):\n",
    "    ax = plt.subplot(4,4,n+1)\n",
    "    plt.imshow(imgs[:,:,n])\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(wspace=0.01,hspace=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build a model to extract features by layer name\n",
    "\n",
    "extracted_features_block1_pool = Model(inputs=features.input, outputs=features.get_layer('block1_pool').output)\n",
    "block1_pool_features = extracted_features_block1_pool.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualise some features from the extracted layer output\n",
    "\n",
    "imgs = block1_pool_features[0,:,:]\n",
    "plt.figure(figsize=(15,15))\n",
    "for n in range(16):\n",
    "    ax = plt.subplot(4,4,n+1)\n",
    "    plt.imshow(imgs[:,:,n])\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(wspace=0.01,hspace=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract features from a layer deeper in the network\n",
    "\n",
    "extracted_features_block5_conv4 = Model(inputs=features.input, outputs=features.get_layer('block5_conv4').output)\n",
    "block5_conv4_features = extracted_features_block5_conv4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualise some features from the extracted layer output\n",
    "\n",
    "imgs = block5_conv4_features_features[0,:,:]\n",
    "plt.figure(figsize=(15,15))\n",
    "for n in range(16):\n",
    "    ax = plt.subplot(4,4,n+1)\n",
    "    plt.imshow(imgs[:,:,n])\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(wspace=0.01,hspace=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## Freezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build a small Sequential model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(4, input_shape=(4,), activation='relu', kernel_initializer='random_uniform',\n",
    "                 bias_initializer='ones'),\n",
    "    layers.Dense(2, activation='relu', kernel_initializer='lecun_normal', bias_initializer='ones'),\n",
    "    layers.Dense(4, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the weight matrix variation over training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model):\n",
    "    return([[e.weights[0].numpy() for e in model.layers]])\n",
    "\n",
    "def get_biases(model):\n",
    "    return([[e.bias.numpy() for e in model.layers]])\n",
    "\n",
    "def plot_delta_weights(W0_layers, W1_layers, b0_layers, b1_layers):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for n in range(3):\n",
    "        delta_l = W1_layers[n] - W0_layers[n]\n",
    "        print('Layer '+str(n)+': bias variation: ', np.linalg.norm(b1_layers[n] - b0_layers[n]))\n",
    "        ax = plt.subplot(1,3,n+1)\n",
    "        plt.imshow(delta_l)\n",
    "        plt.title('Layer '+str(n))\n",
    "        plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.suptitle('Weight matrices variation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieve the weights and biases\n",
    "\n",
    "W0_layers = get_weights(model)\n",
    "b0_layers = get_biases(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Construct a synthetic dataset\n",
    "\n",
    "x_train = np.random.random((100, 4))\n",
    "y_train = x_train\n",
    "\n",
    "x_test = np.random.random((20, 4))\n",
    "y_test = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50, verbose=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieve weights and biases\n",
    "\n",
    "W1_layers = get_weights(model)\n",
    "b1_layers = get_biases(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the variation\n",
    "plot_delta_weights(W0_layers, W1_layers, b0_layers, b1_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeze layers at build time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count the trainable and non trainable variables before the freezing\n",
    "\n",
    "n_trainable_variables = len(model.trainable_variables)\n",
    "n_non_trainable_variables = len(model.non_trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of trainable and non trainable variables before the freezing\n",
    "\n",
    "print(\"\\n Before freezing:\\n\\t Number of trainable variables: \", n_trainable_variables,\n",
    "                         \"\\n\\t Number of non trainable variables: \", n_non_trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(4, input_shape=(4,), activation='relu', kernel_initializer='random_uniform',\n",
    "                 bias_initializer='ones', trainable=False),\n",
    "    layers.Dense(2, activation='relu', kernel_initializer='lecun_normal', bias_initializer='ones'),\n",
    "    layers.Dense(4, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count the trainable and non trainable variables after the freezing\n",
    "\n",
    "n_trainable_variables = len(model.trainable_variables)\n",
    "n_non_trainable_variables = len(model.non_trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of trainable and non trainable variables after the freezing\n",
    "\n",
    "print(\"\\n After freezing:\\n\\t Number of trainable variables: \", n_trainable_variables,\n",
    "                         \"\\n\\t Number of non trainable variables: \", n_non_trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieve weights and biases\n",
    "\n",
    "W0_layers = get_weights(model)\n",
    "b0_layers = get_biases(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(W0_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50, verbose=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieve weights and biases\n",
    "\n",
    "W1_layers = get_weights(model)\n",
    "b1_layers = get_biases(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the variation\n",
    "\n",
    "plot_delta_weights(W0_layers, W1_layers, b0_layers, b1_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeze layers of a pre-built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count the trainable and non trainable variables before the freezing\n",
    "\n",
    "print(\"\\n Before freezing:\\n\\t Number of trainable variables: \", len(model.trainable_variables),\n",
    "                         \"\\n\\t Number of non trainable variables: \", len(model.non_trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Freeze the second layer\n",
    "\n",
    "model.layers[1].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count the trainable and non trainable variables after the freezing\n",
    "\n",
    "print(\"\\n After freezing:\\n\\t Number of trainable variables: \", len(model.trainable_variables),\n",
    "                        \"\\n\\t Number of non trainable variables: \", len(model.non_trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50, verbose=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieve weights and biases\n",
    "\n",
    "W2_layers = get_weights(model)\n",
    "b2_layers = get_biases(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the variation\n",
    "\n",
    "plot_delta_weights(W1_layers, W2_layers, b1_layers, b2_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
